{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85dcf1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b09387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils for baseline training\n",
    "def center_crop(image):\n",
    "    center = image.shape[0] / 2, image.shape[1] / 2\n",
    "    if center[1] < 256 or center[0] < 256:\n",
    "        return cv2.resize(image, (256, 256))\n",
    "    x = center[1] - 128\n",
    "    y = center[0] - 128\n",
    "\n",
    "    return image[int(y):int(y+256), int(x):int(x+256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77581ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 path_gt,\n",
    "                 device='cpu'\n",
    "                ):\n",
    "        \n",
    "        self._items = [] \n",
    "        self._index = 0\n",
    "        self.device = device\n",
    "        dir_img = sorted(os.listdir(path_gt))\n",
    "        img_pathes = dir_img\n",
    "\n",
    "        for img_path in img_pathes:\n",
    "            self._items.append((\n",
    "                os.path.join(path_gt, img_path)\n",
    "            ))\n",
    "        random.shuffle(self._items)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._items)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        gt_path = self._items[index]\n",
    "        image = Image.open(gt_path).convert('RGB')\n",
    "        image = np.array(image).astype(np.float32) \n",
    "\n",
    "        image = center_crop(image)\n",
    "\n",
    "        image = image / 255.\n",
    "        image = transforms.ToTensor()(image)\n",
    "        y = image.to(self.device)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61592dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline UAP training fuction\n",
    "def train(metric_model, path_train, batch_size=8, metric_range=100, device='cpu'):\n",
    "    \"\"\"\n",
    "    UAP adversarial patch training function.\n",
    "    Args:\n",
    "    model: (PyTorch model) Metric model to be attacked. Should be an object of a class that inherits torch.nn.module and has a forward method that supports backpropagation.\n",
    "    path_train: (str) Path to train dataset (Directory with images).\n",
    "    batch_size: (int) Batch size to train UAP with.\n",
    "    device: (str or torch.device()) Device to use in computations.\n",
    "    metric_range: (float) Approximate metric value's range.\n",
    "    Returns:\n",
    "        np.ndarray of shape [H,W,3]: UAP patch\n",
    "    \"\"\"\n",
    "    ds_train = MyCustomDataset(path_gt=path_train, device=device)\n",
    "    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "    eps = 0.1\n",
    "    lr = 0.001\n",
    "    n_epoch = 5\n",
    "    # You can also try random noise\n",
    "    universal_noise = torch.zeros((1, 3, 256, 256)).to(device)\n",
    "    universal_noise += 0.0001\n",
    "    universal_noise = Variable(universal_noise, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([universal_noise], lr=lr)\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        # Iterate over dl_train, optimize patch, update total_loss (sum/mean of epoch losses)\n",
    "        # <YOUR CODE HERE>\n",
    "        ...\n",
    "        print(f'[{epoch} epoch] Total loss: {total_loss}')\n",
    "    return universal_noise.squeeze().data.cpu().numpy().transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8a02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined function to read pretrained patch\n",
    "def read_uap_patch(trained_data_path='../uap_trained_data/pretrained_uap_paq2piq.png'):\n",
    "    \"\"\"\n",
    "    Function to read pretrained patch.\n",
    "    Args:\n",
    "    trained_data_path: (str) path to your pretrained UAP.\n",
    "    Returns:\n",
    "        np.ndarray of shape [H,W,3]: additive that will be passed to attack() during testing.\n",
    "    \"\"\"\n",
    "    uap = cv2.imread(trained_data_path)\n",
    "    uap = cv2.cvtColor(uap, cv2.COLOR_BGR2RGB)\n",
    "    uap = uap.astype('float32') / 255.\n",
    "    uap -= 0.5\n",
    "    return uap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21617fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline UAP attack function. Should apply pretrained adversarial additive to image\n",
    "def attack(image, uap_patch, device='cpu',\n",
    "            eps = 10 / 255,\n",
    "            ):\n",
    "    \"\"\"\n",
    "    Attack function.\n",
    "    Args:\n",
    "    image: (torch.Tensor of shape [1,3,H,W]) clear image to be attacked.\n",
    "    uap_patch: adversarial additive read with read_uap_patch(). Should be same for all images.\n",
    "    device (str or torch.device()): Device to use in computaions.\n",
    "    eps: (float) maximum allowed pixel-wise difference between clear and attacked images (in 0-1 scale).\n",
    "    Returns:\n",
    "        torch.Tensor of shape [1,3,H,W]: adversarial image with same shape as image argument.\n",
    "    \"\"\"\n",
    "    image = image.to(device)\n",
    "\n",
    "    h, w = image.shape[2], image.shape[3]\n",
    "    uap_h, uap_w = uap_patch.shape[0], uap_patch.shape[1]\n",
    "\n",
    "    # Resize UAP patch or tile it to match image resolution, then move it to device\n",
    "    uap_resized = ...\n",
    "\n",
    "    # UAP pixels after baseline training are in [-0.1, 0.1] range, so (10 * eps) multiplier will limit them to [-eps, eps]\n",
    "    uap_multiplier = 10 * eps\n",
    "    attacked_image = image + uap_resized * uap_multiplier\n",
    "    return torch.clamp(attacked_image, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7b4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
